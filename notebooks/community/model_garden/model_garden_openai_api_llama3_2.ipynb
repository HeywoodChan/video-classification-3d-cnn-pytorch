{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeywoodChan/video-classification-3d-cnn-pytorch/blob/master/notebooks/community/model_garden/model_garden_openai_api_llama3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to get started with using the OpenAI library and demonstrates how to leverage multimodal capabilities of Llama 3.2 models as Model-as-service (MaaS).\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Configure OpenAI SDK for the Llama 3.2 Completions API\n",
        "- Chat with Llama 3.2 models with different prompts and model parameters\n",
        "- Build and use Llama 3.2 GenAI powered application for Car Damage Assessment.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform openai gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"upheld-quanta-442214-i7\"  # @param {type:\"string\"}\n",
        "\n",
        "# Only `us-central1` is supported region for Llama 3.2 models using Model-as-a-Service (MaaS).\n",
        "LOCATION = \"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store tutorial artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"cuhk_fashion_report_2024_image_batch1\"  # @param {type:\"string\"}\n",
        "\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "NIq7R4HZCfIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38246399-917f-4562-ff27-dc853012eef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://cuhk_fashion_report_2024_image_batch1/...\n",
            "ServiceException: 409 A Cloud Storage bucket named 'cuhk_fashion_report_2024_image_batch1' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
          ]
        }
      ],
      "source": [
        "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wn8ZkcV86KR"
      },
      "source": [
        "### Initialize Vertex AI SDK for Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "B8DawN9D9NLU"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVYoyDl165EE"
      },
      "source": [
        "### Import libraries\n",
        "\n",
        "Import libraries to use in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "c1tEW-U968h8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import uuid\n",
        "from io import BytesIO\n",
        "\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "# Chat completions API\n",
        "import openai\n",
        "from google.auth import default, transport\n",
        "from google.cloud import storage\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "do6pdqyLSJif"
      },
      "outputs": [],
      "source": [
        "def visualize_image_from_bucket(bucket_name: str, blob_name: str) -> None:\n",
        "    \"\"\"Visualizes an image stored in a Google Cloud Storage bucket.\"\"\"\n",
        "    try:\n",
        "        # Create a client for interacting with Google Cloud Storage\n",
        "        storage_client = storage.Client()\n",
        "\n",
        "        # Get a reference to the bucket and blob\n",
        "        bucket = storage_client.bucket(bucket_name)\n",
        "        blob = bucket.blob(blob_name)\n",
        "\n",
        "        # Download the image data into memory\n",
        "        image_data = blob.download_as_bytes()\n",
        "\n",
        "        # Open the image using PIL\n",
        "        image = Image.open(BytesIO(image_data))\n",
        "\n",
        "        # Display the image using matplotlib\n",
        "        plt.figure(figsize=(10, 10))  # Set the figure size (adjust as needed)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")  # Turn off axis labels\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error visualizing image: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqYCG2Fw7D3L"
      },
      "source": [
        "### Configure OpenAI SDK for the Llama 3.2 Chat Completions API\n",
        "\n",
        "To configure the OpenAI SDK for the Llama 3.2 Chat Completions API, you need to request the access token and initialize the client pointing to the Llama 3.2 endpoint.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0K6VSJRHhH2"
      },
      "source": [
        "#### Authentication\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "i0qceuiQEPHv"
      },
      "outputs": [],
      "source": [
        "credentials, _ = default()\n",
        "auth_request = transport.requests.Request()\n",
        "credentials.refresh(auth_request)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q04wJmA0HT6X"
      },
      "source": [
        "Then configure the OpenAI SDK to point to the Llama 3.2 Chat Completions API endpoint.\n",
        "\n",
        "Notice, only `us-central1` is supported region for Llama 3.2 models using Model-as-a-Service (MaaS)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "c-MRhsnlj6iw"
      },
      "outputs": [],
      "source": [
        "MODEL_LOCATION = \"us-central1\"\n",
        "MAAS_ENDPOINT = f\"{MODEL_LOCATION}-aiplatform.googleapis.com\"\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    base_url=f\"https://{MAAS_ENDPOINT}/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi\",\n",
        "    api_key=credentials.token,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGokrtdiIHrX"
      },
      "source": [
        "#### Llama 3.2 models\n",
        "\n",
        "You can experiment with various supported Llama 3.2 models.\n",
        "\n",
        "This tutorial use Llama 3.2 90B Vision Instruct using Model-as-a-Service (MaaS). Using Model-as-a-Service (MaaS), you can access Llama 3.2 models in just a few clicks without any setup or infrastructure hassles.\n",
        "\n",
        "You can also access Llama models for self-service in Vertex AI Model Garden, allowing you to choose your preferred infrastructure. [Check out Llama 3.2 model card](https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama3-2?_ga=2.31261500.2048242469.1721714335-1107467625.1721655511) to learn how to deploy a Llama 3.2 models on Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "id": "r7OhyH46H2H5"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"meta/llama-3.2-90b-vision-instruct-maas\"  # @param {type:\"string\"} [\"meta/llama-3.2-90b-vision-instruct-maas\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xD62NTpqHXd"
      },
      "source": [
        "### Chat with Llama 3.2\n",
        "\n",
        "Use the Chat Completions API to send a multi-model request to the Llama 3.2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkyp9kZSuJGx"
      },
      "source": [
        "#### Hello, Llama 3.2 90B  Yeah!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Background:\n",
        "I am conducting a data science master's project focused on analyzing 10,000 fashion images to extract detailed attributes for each item. Your task is to meticulously analyze each image and identify specific attributes from the provided categories. The output must adhere strictly to the JSON format illustrated in the example below. Ensure high accuracy and consistency in your classifications to facilitate downstream data analysis.\n",
        "\n",
        "________________________________________\n",
        "Instructions:\n",
        "1. Category Selection:\n",
        "   For each fashion item image, identify and classify attributes based on the following categories. Each category is uniquely numbered and precisely defined to ensure comprehensive and granular data collection.\n",
        "\n",
        "   • **Category 0: Fashion Main Category**\n",
        "       - **Description:** Broad primary categories encompassing all types of fashion items.\n",
        "       - **Examples:** Clothing, Footwear, Accessories, Outerwear, Bags, Jewelry, Hats.\n",
        "\n",
        "   • **Category 1: Fashion Item Sub Category**\n",
        "       - **Description:** Specific subcategories under each main category for precise classification.\n",
        "       - **Examples:** Blazer, Jeans, T-Shirt, Sneakers, Handbag, Necklace, Fedora.\n",
        "\n",
        "   • **Category 2: Patterns**\n",
        "       - **Description:** The arrangement of forms, lines, or shapes on the surface of the fashion item, contributing to its aesthetic appeal.\n",
        "       - **Examples:** Stripes, Polka Dots, Chevron, Houndstooth, Paisley, Geometric, Abstract, None.\n",
        "\n",
        "   • **Category 3: Prints**\n",
        "       - **Description:** Repeated decorative designs or motifs applied to the fabric or surface of the fashion item.\n",
        "       - **Examples:** Floral Print, Animal Print, Camouflage Print, Graphic Prints, Artistic Prints, Tie-Dye, Digital Prints, None.\n",
        "\n",
        "   • **Category 4: Graphics**\n",
        "       - **Description:** Illustrations, logos, text, or other visual elements that are part of the fashion item's design.\n",
        "       - **Examples:** Logo Embroidery, Graphic Tees, Statement Text, Brand Symbols, Decorative Illustrations, Minimalist Graphics, None.\n",
        "\n",
        "   • **Category 5: Materials, Fabrics, and Finishes**\n",
        "       - **Description:** Specifies the materials, fabric compositions, and finishes used in the item.\n",
        "       - **Examples:** 100% Merino Wool, Modal Fiber Blend, Recycled Polyester, Brushed Chenille, Organic Cotton, Denim, Leather, Satin.\n",
        "\n",
        "   • **Category 6: Fit**\n",
        "       - **Description:** Describes how the clothing item fits the body, indicating the intended silhouette.\n",
        "       - **Examples:** Fitted, Relaxed, Oversized, Tailored, Slim, Regular, Loose.\n",
        "\n",
        "   • **Category 7: Silhouette**\n",
        "       - **Description:** Refers to the overall shape or outline of the garment, contributing to its style and appearance.\n",
        "       - **Examples:** Slim, Boxy, A-line, Straight, Flared, Peplum, Structured.\n",
        "\n",
        "   • **Category 8: Length**\n",
        "       - **Description:** Indicates the length of the clothing item, providing information on its coverage.\n",
        "       - **Examples:** Mini, Knee-length, Midi, Ankle, Maxi, Cropped, Floor-length.\n",
        "\n",
        "   • **Category 9: Design Features**\n",
        "       - **Description:** Highlights specific design elements and structural features of the garment.\n",
        "       - **Examples:** Double-breasted, Notched Collar, Asymmetric Hem, Patch Pockets, Zipper Closures, Embroidery, Sequins, Ruffles, Buttons, Belted Waist.\n",
        "\n",
        "   • **Category 10: Embellishments**\n",
        "       - **Description:** Details any additional decorative elements that enhance the item's aesthetic.\n",
        "       - **Examples:** Embroidery, Sequins, Patches, Appliqués, Beading, Rhinestones, Lace.\n",
        "\n",
        "   • **Category 11: Style**\n",
        "       - **Description:** Refers to the distinctive appearance or design characteristic of the fashion item, aligned with specific fashion movements or personal aesthetics.\n",
        "       - **Examples:** Classic, Minimalist, Bohemian, Streetwear, High-Fashion, Eclectic, Sporty, Preppy.\n",
        "\n",
        "   • **Category 12: Theme**\n",
        "       - **Description:** The underlying subject or motif that gives direction to the design of the fashion item.\n",
        "       - **Examples:** Nautical, Military, Vintage, Futuristic, Tropical, Gothic, Romantic, Urban.\n",
        "\n",
        "   • **Category 13: Overall Inspiration**\n",
        "       - **Description:** The primary influence or source of creativity behind the fashion item's design, reflecting cultural, artistic, or temporal inspirations.\n",
        "       - **Examples:** Audrey Hepburn-inspired, Americana, Retro, Avant-garde, Sustainable, Eclectic, Bohemian, Futuristic.\n",
        "\n",
        "   • **Category 14: Main Color**\n",
        "       - **Description:** The dominant color of the fashion item, serving as the primary visual identifier.\n",
        "       - **Examples:** White, Black, Red, Blue, Green, Yellow, Pink, Purple, Neutral Tones, Pastels, Metallics, Pantone 11-0602 TCX (White), Pantone 14-0852 TCX (Spectra Yellow).\n",
        "\n",
        "   • **Category 15: Sub Color**\n",
        "       - **Description:** Secondary or accent colors present in the item that complement or contrast with the main color.\n",
        "       - **Examples:** Off-white, Cream, Light Beige, Ivory, Neon Green, Metallic Silver, Navy Blue, Dusty Rose, Burnt Orange, Sky Blue, Teal, Burgundy.\n",
        "\n",
        "   • **Category 16: Usage Categories**\n",
        "       - **Description:** Contexts or occasions for which the item is intended, indicating its suitability for specific events or activities.\n",
        "       - **Examples:** Formal Wear, Casual, Business Casual, Athletic, Evening Wear, Streetwear, Resort Wear, Wedding, Office, Party, Travel, Outdoor, Beachwear.\n",
        "\n",
        "   • **Category 17: Gender-Based Categories**\n",
        "       - **Description:** Specifies the intended gender for the fashion item, reflecting design and sizing considerations.\n",
        "       - **Examples:** Male, Female, Non-binary, Gender Fluid, Unisex, Androgynous.\n",
        "\n",
        "   • **Category 18: Seasonality**\n",
        "       - **Description:** Specifies the season(s) the item is designed for, indicating appropriate materials and designs for weather conditions.\n",
        "       - **Examples:** Spring, Summer, Fall, Winter, All-Season, Transitional.\n",
        "\n",
        "   • **Category 19: Embellishments and Accessories**\n",
        "       - **Description:** Details any additional decorative elements or attached accessories that enhance functionality or style.\n",
        "       - **Examples:** Belts, Hoods, Scarves, Patches, Appliqués, Buckles, Chains, Pompoms.\n",
        "\n",
        "   • **Category 20: Closure Type**\n",
        "       - **Description:** Describes how the garment is fastened, affecting both functionality and style.\n",
        "       - **Examples:** Buttons, Zipper, Hook and Loop, Tie, Snap, Buckle, Magnetic Closures, Velcro.\n",
        "\n",
        "   • **Category 21: Target Age Group**\n",
        "       - **Description:** Specifies the intended age demographic for the fashion item, guiding design and marketing strategies.\n",
        "       - **Examples:** Teens (13-19), Young Adults (20-30), Adults (31-50), Seniors (51+), Children (Under 13), All Ages, Toddlers (1-3).\n",
        "\n",
        "   • **Category 22: Popularity and Sales Status**\n",
        "       - **Description:** Indicates whether the fashion item is currently popular or a hot-selling item in 2023, reflecting market trends and consumer demand.\n",
        "       - **Examples:**\n",
        "           - **Highly Popular:** Widely recognized and sought after, frequently featured in fashion media.\n",
        "           - **Trending:** Gaining popularity rapidly, often seen in influencer posts and social media platforms.\n",
        "           - **Moderately Popular:** Known within certain demographics or regions, maintaining steady sales.\n",
        "           - **Not Popular:** Limited recognition and low sales figures.\n",
        "           - **Unknown:** Popularity cannot be determined from the available information.\n",
        "\n",
        "2. Attention to Detail:\n",
        "   - Examine every aspect of the fashion item, ensuring that no attribute is overlooked.\n",
        "   - Consider elements such as stitching, texture, embellishment placement, and unique design aspects that may not be immediately apparent.\n",
        "   - If an attribute spans multiple categories (e.g., a patterned fabric with a specific closure type), ensure each category is accurately populated.\n",
        "\n",
        "3. Consistency and Accuracy:\n",
        "   - Maintain uniformity in category responses to facilitate reliable data aggregation.\n",
        "   - Avoid ambiguous or subjective terms; choose the most precise term from the provided examples.\n",
        "   - In cases where multiple applicable examples exist, prioritize based on prominence and visibility in the image.\n",
        "\n",
        "4. Handling Uncertainty:\n",
        "   - If an attribute is not discernible from the image, default to \"Unknown\" rather than \"N/A\" unless **Category 0** explicitly dictates otherwise.\n",
        "   - Ensure that \"Unknown\" is used judiciously to reflect genuine uncertainty without compromising data integrity.\n",
        "\n",
        "#### 2. Output Format:\n",
        "• Your response should be **only** a JSON object covering Categories 0 to 22.\n",
        "• If **Category 0** is selected as \"Other\", \"Not Applicable\", or \"N/A\", set all Categories 1 to 22 to \"N/A\".\n",
        "• Follow the JSON example below **precisely**. Do **not** include any additional text or explanations beyond the JSON structure.\n",
        "\n",
        "#### 3. JSON Example:\n",
        "```json\n",
        "{\n",
        "  \"Category 0: Fashion Main Category\": \"Clothing\",\n",
        "  \"Category 1: Fashion Item Sub Category\": \"Blazer\",\n",
        "  \"Category 2: Patterns\": \"Stripes\",\n",
        "  \"Category 3: Prints\": \"Graphic Prints\",\n",
        "  \"Category 4: Graphics\": \"Logo Embroidery\",\n",
        "  \"Category 5: Materials, Fabrics, and Finishes\": \"100% Merino Wool\",\n",
        "  \"Category 6: Fit\": \"Fitted\",\n",
        "  \"Category 7: Silhouette\": \"Tailored\",\n",
        "  \"Category 8: Length\": \"Ankle-length\",\n",
        "  \"Category 9: Design Features\": \"Double-breasted, Notched Collar, Asymmetric Hem\",\n",
        "  \"Category 10: Embellishments\": \"Sequins\",\n",
        "  \"Category 11: Style\": \"Classic\",\n",
        "  \"Category 12: Theme\": \"Americana\",\n",
        "  \"Category 13: Overall Inspiration\": \"Audrey Hepburn-inspired\",\n",
        "  \"Category 14: Main Color\": \"White, Pantone 11-0602 TCX\",\n",
        "  \"Category 15: Sub Color\": \"Off-white, Cream\",\n",
        "  \"Category 16: Usage Categories\": \"Formal Wear\",\n",
        "  \"Category 17: Gender-Based Categories\": \"Unisex\",\n",
        "  \"Category 18: Seasonality\": \"Winter\",\n",
        "  \"Category 19: Embellishments and Accessories\": \"None\",\n",
        "  \"Category 20: Closure Type\": \"Buttons\",\n",
        "  \"Category 21: Target Age Group\": \"Young Adults (20-30)\",\n",
        "  \"Category 22: Popularity and Sales Status\": \"Trending\"\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "23lIKPMfwfG2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# 5. Define Constants and Initialize DataFrame\n",
        "# =====================================\n",
        "\n",
        "# GCS bucket details\n",
        "BUCKET_NAME = 'cuhk_fashion_project_2024_batch_1'\n",
        "PREFIX = ''  # If your images are in a subfolder, specify the prefix; empty string lists all\n",
        "\n",
        "# Path to save the Excel file in Google Drive\n",
        "EXCEL_FILE_PATH = '/content/drive/MyDrive/fashion_report_2024_results.xlsx'\n",
        "\n",
        "# Define the categories (Category 0 to Category 22)\n",
        "num_categories = 23\n",
        "category_names = [f\"Category {i}\" for i in range(num_categories)]\n",
        "\n",
        "# Additional columns for image path and image name\n",
        "additional_columns = ['image_path', 'image_name']\n",
        "\n",
        "# Complete list of columns\n",
        "all_columns = additional_columns + category_names\n",
        "\n",
        "# Delete the original Excel file if it exists to start fresh\n",
        "if os.path.exists(EXCEL_FILE_PATH):\n",
        "    os.remove(EXCEL_FILE_PATH)\n",
        "    print(f\"Deleted existing Excel file at {EXCEL_FILE_PATH}\")\n",
        "\n",
        "# Initialize the DataFrame with image_path, image_name, and categories\n",
        "df = pd.DataFrame(columns=all_columns)\n",
        "print(\"Initialized new DataFrame with 'image_path' and 'image_name' columns.\")\n",
        "\n",
        "# =====================================\n",
        "# 6. Define the API Call Function\n",
        "# =====================================\n",
        "\n",
        "# Import your actual API client library if different\n",
        "# For example, for Llama's API, ensure you have the correct client installed and imported\n",
        "# Replace the following with actual imports if needed\n",
        "\n",
        "# Placeholder for the Llama API client initialization\n",
        "# Replace with actual client setup code\n",
        "# Example:\n",
        "# from llama_client import LlamaClient\n",
        "# client = LlamaClient(api_key='YOUR_API_KEY')\n",
        "\n",
        "# Define your MODEL_ID\n",
        "# Replace 'your-model-id' with the actual model ID you intend to use\n",
        "MODEL_ID = 'your-model-id'\n",
        "\n",
        "def call_llama_api(image_url, prompt, max_tokens=4096, temperature=1.0, top_p=1.0):\n",
        "    \"\"\"\n",
        "    Calls the Llama API with the given image URL and prompt.\n",
        "\n",
        "    Args:\n",
        "        image_url (str): The GCS URL of the image.\n",
        "        prompt (str): The prompt to send along with the image.\n",
        "        max_tokens (int): Maximum tokens in the response.\n",
        "        temperature (float): Sampling temperature.\n",
        "        top_p (float): Nucleus sampling parameter.\n",
        "\n",
        "    Returns:\n",
        "        response (dict): The API response.\n",
        "    \"\"\"\n",
        "    # Replace the following code with your actual API call\n",
        "    max_tokens = 4096\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_ID,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"image_url\": {\n",
        "                            \"url\": image_url\n",
        "                        },\n",
        "                        \"type\": \"image_url\",\n",
        "                    },\n",
        "                    {\"text\": prompt, \"type\": \"text\"},\n",
        "                ],\n",
        "            },\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        top_p=top_p\n",
        "    )\n",
        "\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "    return response\n",
        "\n",
        "# =====================================\n",
        "# 7. Define Function to Parse API Response\n",
        "# =====================================\n",
        "\n",
        "def parse_response(response_content):\n",
        "    \"\"\"\n",
        "    Parses the JSON response content and extracts category values.\n",
        "\n",
        "    Args:\n",
        "        response_content (str): The JSON string from the API response.\n",
        "\n",
        "    Returns:\n",
        "        parsed_data (list): List of category values from Category 0 to Category 22.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = json.loads(response_content)\n",
        "        parsed_data = []\n",
        "        for i in range(num_categories):\n",
        "            # Find the key that starts with 'Category i:'\n",
        "            category_key = next((k for k in data.keys() if k.startswith(f\"Category {i}:\")), None)\n",
        "            if category_key:\n",
        "                value = data.get(category_key, \"N/A\")\n",
        "            else:\n",
        "                value = \"N/A\"\n",
        "            parsed_data.append(value)\n",
        "        return parsed_data\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Failed to decode JSON response.\")\n",
        "        return [\"N/A\"] * num_categories\n",
        "\n",
        "# =====================================\n",
        "# 8. Define Function to Check All Categories N/A\n",
        "# =====================================\n",
        "\n",
        "def all_na(parsed_data):\n",
        "    \"\"\"\n",
        "    Checks if all category values are 'N/A'.\n",
        "\n",
        "    Args:\n",
        "        parsed_data (list): List of category values.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if all categories are 'N/A', False otherwise.\n",
        "    \"\"\"\n",
        "    return all(value.strip().upper() == \"N/A\" for value in parsed_data if isinstance(value, str))\n",
        "\n",
        "# =====================================\n",
        "# 9. List All Images in the GCS Bucket (Including Subfolders)\n",
        "# =====================================\n",
        "\n",
        "def list_gcs_images(bucket_name, prefix=''):\n",
        "    \"\"\"\n",
        "    Lists all image files in the specified GCS bucket and prefix, including subfolders.\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): The name of the GCS bucket.\n",
        "        prefix (str): The prefix path in the bucket (use '' to list all).\n",
        "\n",
        "    Returns:\n",
        "        image_urls (list): List of GCS URLs for image files.\n",
        "    \"\"\"\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs(prefix=prefix)\n",
        "    image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp')\n",
        "    image_urls = [f\"gs://{bucket_name}/{blob.name}\" for blob in blobs if blob.name.lower().endswith(image_extensions)]\n",
        "    return image_urls\n",
        "\n",
        "# =====================================\n",
        "# 10. Main Processing Loop\n",
        "# =====================================\n",
        "\n",
        "# Define your prompt here\n",
        "prompt = \"Please classify the fashion item in the image based on the provided categories.\"\n",
        "\n",
        "# List all image URLs in the GCS bucket (including all subfolders)\n",
        "image_urls = list_gcs_images(BUCKET_NAME, PREFIX)\n",
        "total_images = len(image_urls)\n",
        "print(f\"Total images found: {total_images}\")\n",
        "\n",
        "# Iterate through each image\n",
        "for idx, image_url in enumerate(image_urls, 1):\n",
        "    print(f\"\\nProcessing image {idx}/{total_images}: {image_url}\")\n",
        "    retries = 0\n",
        "    max_retries = 3\n",
        "    success = False\n",
        "\n",
        "    while retries < max_retries and not success:\n",
        "        try:\n",
        "            # Call the API\n",
        "            response = call_llama_api(image_url, prompt)\n",
        "            response_content = response['choices'][0]['message']['content']\n",
        "\n",
        "            # Parse the response\n",
        "            parsed_data = parse_response(response_content)\n",
        "\n",
        "            # Check if all categories are 'N/A'\n",
        "            if all_na(parsed_data):\n",
        "                retries += 1\n",
        "                print(f\"All categories returned as 'N/A'. Retry {retries}/{max_retries} after delay.\")\n",
        "                time.sleep(5)  # Wait before retrying\n",
        "            else:\n",
        "                success = True\n",
        "        except Exception as e:\n",
        "            retries += 1\n",
        "            print(f\"Error during API call: {e}. Retry {retries}/{max_retries} after delay.\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    if not success:\n",
        "        print(f\"Failed to process image after {max_retries} retries. Appending 'N/A' for all categories.\")\n",
        "        parsed_data = [\"N/A\"] * num_categories\n",
        "\n",
        "    # Extract image path and image name\n",
        "    # For GCS URLs like gs://bucket/folder/subfolder/image.jpg\n",
        "    # image_path should be gs://bucket/folder/subfolder/\n",
        "    # image_name should be image.jpg\n",
        "    try:\n",
        "        # Remove 'gs://' prefix\n",
        "        path_without_scheme = image_url[5:]\n",
        "        # Split into bucket and the rest of the path\n",
        "        bucket_part, path_part = path_without_scheme.split('/', 1)\n",
        "        # Get image_path by removing the image name\n",
        "        image_path = f\"gs://{bucket_part}/{os.path.dirname(path_part)}/\"\n",
        "        # Get image_name\n",
        "        image_name = os.path.basename(path_part)\n",
        "    except ValueError:\n",
        "        # Handle cases where there might not be a subfolder\n",
        "        # e.g., gs://bucket/image.jpg\n",
        "        bucket_part = image_url[5:].split('/', 1)[0]\n",
        "        image_path = f\"gs://{bucket_part}/\"\n",
        "        image_name = os.path.basename(image_url)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing image URL '{image_url}': {e}\")\n",
        "        image_path = image_url  # Fallback to full URL\n",
        "        image_name = 'Unknown'\n",
        "\n",
        "    # Create a dictionary for the new row, including image_path and image_name\n",
        "    row_dict = {\n",
        "        'image_path': image_path,\n",
        "        'image_name': image_name\n",
        "    }\n",
        "    row_dict.update({category_names[i]: parsed_data[i] for i in range(num_categories)})\n",
        "\n",
        "    # Convert the row dictionary to a DataFrame\n",
        "    new_row = pd.DataFrame([row_dict])\n",
        "\n",
        "    # Concatenate the new row to the existing DataFrame\n",
        "    df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "    # Save the updated DataFrame to Excel with support for Chinese characters\n",
        "    try:\n",
        "        df.to_excel(EXCEL_FILE_PATH, index=False, engine='openpyxl')\n",
        "        print(f\"Saved results to {EXCEL_FILE_PATH}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving to Excel: {e}\")\n",
        "\n",
        "    # Optional: Introduce a short delay to respect API rate limits\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"\\nProcessing completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "xjJtEBJJBhdA",
        "outputId": "df5e5801-a601-46bb-c7cc-80f351297eec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized new DataFrame with 'image_path' and 'image_name' columns.\n",
            "Total images found: 300\n",
            "\n",
            "Processing image 1/300: gs://cuhk_fashion_project_2024_batch_1/Ellasay/ELLASSAY_歌力思_1.jpg\n",
            "Error during API call: Error code: 400 - [{'error': {'code': 400, 'message': \"Malformed publisher model (`model`: 'your-model-id') for the 'openapi' request endpoint ID; expected '<publisher>/<model>'.\", 'status': 'INVALID_ARGUMENT'}}]. Retry 1/3 after delay.\n",
            "Error during API call: Error code: 400 - [{'error': {'code': 400, 'message': \"Malformed publisher model (`model`: 'your-model-id') for the 'openapi' request endpoint ID; expected '<publisher>/<model>'.\", 'status': 'INVALID_ARGUMENT'}}]. Retry 2/3 after delay.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-b13500115dae>\u001b[0m in \u001b[0;36m<cell line: 171>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# Call the API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_llama_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mresponse_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'choices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-b13500115dae>\u001b[0m in \u001b[0;36mcall_llama_api\u001b[0;34m(image_url, prompt, max_tokens, temperature, top_p)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1277\u001b[0m         )\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - [{'error': {'code': 400, 'message': \"Malformed publisher model (`model`: 'your-model-id') for the 'openapi' request endpoint ID; expected '<publisher>/<model>'.\", 'status': 'INVALID_ARGUMENT'}}]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-b13500115dae>\u001b[0m in \u001b[0;36m<cell line: 171>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mretries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error during API call: {e}. Retry {retries}/{max_retries} after delay.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens = 4096\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL_ID,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"gs://cuhk_fashion_project_2024_batch_1/Ellasay/ELLASSAY_歌力思_1.jpg\"\n",
        "                    },\n",
        "                    \"type\": \"image_url\",\n",
        "                },\n",
        "                {\"text\": prompt, \"type\": \"text\"},\n",
        "            ],\n",
        "        },\n",
        "    ],\n",
        "    temperature=1.0,\n",
        "    max_tokens=max_tokens,\n",
        "    top_p=1.0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "oKmnuNPNCoSw",
        "outputId": "08ee6ec8-4107-45cb-aaa8-aac99a3389e4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Error code: 404 - [{'error': {'code': 404, 'message': 'Publisher Model `projects/324474596293/locations/us-central1/publishers/publisher/models/model` not found.', 'status': 'NOT_FOUND'}}]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-901ab078bacf>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    827\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         )\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - [{'error': {'code': 404, 'message': 'Publisher Model `projects/324474596293/locations/us-central1/publishers/publisher/models/model` not found.', 'status': 'NOT_FOUND'}}]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# 0. Preliminary Setup\n",
        "# =====================================\n",
        "\n",
        "# Ensure that you have the necessary permissions and have uploaded your service account JSON key to Google Drive.\n",
        "\n",
        "# =====================================\n",
        "# 1. Install Necessary Libraries\n",
        "# =====================================\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 5. Define Constants and Initialize DataFrame\n",
        "# =====================================\n",
        "\n",
        "# GCS bucket details\n",
        "BUCKET_NAME = 'cuhk_fashion_project_2024_batch_1'  # Updated bucket name based on your error log\n",
        "PREFIX = ''  # Use empty string to list all subfolders\n",
        "\n",
        "# Path to save the Excel file in Google Drive\n",
        "EXCEL_FILE_PATH = '/content/drive/MyDrive/fashion_report_2024_results.xlsx'\n",
        "\n",
        "# Define the categories (Category 0 to Category 22)\n",
        "num_categories = 23\n",
        "category_names = [f\"Category {i}\" for i in range(num_categories)]\n",
        "\n",
        "# Additional columns for image path and image name\n",
        "additional_columns = ['image_path', 'image_name']\n",
        "\n",
        "# Complete list of columns\n",
        "all_columns = additional_columns + category_names\n",
        "\n",
        "# Delete the original Excel file if it exists to start fresh\n",
        "if os.path.exists(EXCEL_FILE_PATH):\n",
        "    os.remove(EXCEL_FILE_PATH)\n",
        "    print(f\"Deleted existing Excel file at {EXCEL_FILE_PATH}\")\n",
        "\n",
        "# Initialize the DataFrame with image_path, image_name, and categories\n",
        "df = pd.DataFrame(columns=all_columns)\n",
        "print(\"Initialized new DataFrame with 'image_path' and 'image_name' columns.\")\n",
        "\n",
        "# =====================================\n",
        "# 6. Define the API Call Function\n",
        "# =====================================\n",
        "\n",
        "# Initialize your API client\n",
        "# Example for Llama's API (replace with actual initialization)\n",
        "# client = LlamaClient(api_key='YOUR_API_KEY')\n",
        "\n",
        "# Define your MODEL_ID\n",
        "# IMPORTANT: Replace the below MODEL_ID with your actual model identifier.\n",
        "# The format typically follows `<publisher>/<model>`\n",
        "# Example (hypothetical): 'llama-ai/llama-3.2-90B'\n",
        "MODEL_ID = 'llama-ai/llama-3.2-90B'  # Replace with your actual model ID\n",
        "\n",
        "def call_llama_api(image_url, prompt, max_tokens=4096, temperature=1.0, top_p=1.0):\n",
        "    \"\"\"\n",
        "    Calls the Llama API with the given image URL and prompt.\n",
        "\n",
        "    Args:\n",
        "        image_url (str): The GCS URL of the image.\n",
        "        prompt (str): The prompt to send along with the image.\n",
        "        max_tokens (int): Maximum tokens in the response.\n",
        "        temperature (float): Sampling temperature.\n",
        "        top_p (float): Nucleus sampling parameter.\n",
        "\n",
        "    Returns:\n",
        "        response (dict): The API response.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Make the actual API call\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL_ID,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"image_url\": {\n",
        "                                \"url\": image_url\n",
        "                            },\n",
        "                            \"type\": \"image_url\",\n",
        "                        },\n",
        "                        {\"text\": prompt, \"type\": \"text\"},\n",
        "                    ],\n",
        "                },\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "            top_p=top_p\n",
        "        )\n",
        "\n",
        "        # Print the response content (optional)\n",
        "        print(response.choices[0].message.content)\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed: {e}\")\n",
        "        raise  # Re-raise exception to handle retries in the main loop\n",
        "\n",
        "# =====================================\n",
        "# 7. Define Function to Parse API Response\n",
        "# =====================================\n",
        "\n",
        "def parse_response(response_content):\n",
        "    \"\"\"\n",
        "    Parses the JSON response content and extracts category values.\n",
        "\n",
        "    Args:\n",
        "        response_content (str): The JSON string from the API response.\n",
        "\n",
        "    Returns:\n",
        "        parsed_data (list): List of category values from Category 0 to Category 22.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = json.loads(response_content)\n",
        "        parsed_data = []\n",
        "        for i in range(num_categories):\n",
        "            # Find the key that starts with 'Category i:'\n",
        "            category_key = next((k for k in data.keys() if k.startswith(f\"Category {i}:\")), None)\n",
        "            if category_key:\n",
        "                value = data.get(category_key, \"N/A\")\n",
        "            else:\n",
        "                value = \"N/A\"\n",
        "            parsed_data.append(value)\n",
        "        return parsed_data\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Failed to decode JSON response.\")\n",
        "        return [\"N/A\"] * num_categories\n",
        "\n",
        "# =====================================\n",
        "# 8. Define Function to Check All Categories N/A\n",
        "# =====================================\n",
        "\n",
        "def all_na(parsed_data):\n",
        "    \"\"\"\n",
        "    Checks if all category values are 'N/A'.\n",
        "\n",
        "    Args:\n",
        "        parsed_data (list): List of category values.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if all categories are 'N/A', False otherwise.\n",
        "    \"\"\"\n",
        "    return all(value.strip().upper() == \"N/A\" for value in parsed_data if isinstance(value, str))\n",
        "\n",
        "# =====================================\n",
        "# 9. List All Images in the GCS Bucket (Including Subfolders)\n",
        "# =====================================\n",
        "\n",
        "def list_gcs_images(bucket_name, prefix=''):\n",
        "    \"\"\"\n",
        "    Lists all image files in the specified GCS bucket and prefix, including subfolders.\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): The name of the GCS bucket.\n",
        "        prefix (str): The prefix path in the bucket (use '' to list all).\n",
        "\n",
        "    Returns:\n",
        "        image_urls (list): List of GCS URLs for image files.\n",
        "    \"\"\"\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs(prefix=prefix)\n",
        "    image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp')\n",
        "    image_urls = [f\"gs://{bucket_name}/{blob.name}\" for blob in blobs if blob.name.lower().endswith(image_extensions)]\n",
        "    return image_urls\n",
        "\n",
        "# =====================================\n",
        "# 10. Main Processing Loop\n",
        "# =====================================\n",
        "\n",
        "# Define your prompt here\n",
        "prompt = \"Please classify the fashion item in the image based on the provided categories.\"\n",
        "\n",
        "# List all image URLs in the GCS bucket (including all subfolders)\n",
        "image_urls = list_gcs_images(BUCKET_NAME, PREFIX)\n",
        "total_images = len(image_urls)\n",
        "print(f\"Total images found: {total_images}\")\n",
        "\n",
        "# Iterate through each image\n",
        "for idx, image_url in enumerate(image_urls, 1):\n",
        "    print(f\"\\nProcessing image {idx}/{total_images}: {image_url}\")\n",
        "    retries = 0\n",
        "    max_retries = 3\n",
        "    success = False\n",
        "\n",
        "    while retries < max_retries and not success:\n",
        "        try:\n",
        "            # Call the API\n",
        "            response = call_llama_api(image_url, prompt)\n",
        "            response_content = response['choices'][0]['message']['content']\n",
        "\n",
        "            # Parse the response\n",
        "            parsed_data = parse_response(response_content)\n",
        "\n",
        "            # Check if all categories are 'N/A'\n",
        "            if all_na(parsed_data):\n",
        "                retries += 1\n",
        "                print(f\"All categories returned as 'N/A'. Retry {retries}/{max_retries} after delay.\")\n",
        "                time.sleep(5)  # Wait before retrying\n",
        "            else:\n",
        "                success = True\n",
        "        except Exception as e:\n",
        "            retries += 1\n",
        "            print(f\"Error during API call: {e}. Retry {retries}/{max_retries} after delay.\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    if not success:\n",
        "        print(f\"Failed to process image after {max_retries} retries. Appending 'N/A' for all categories.\")\n",
        "        parsed_data = [\"N/A\"] * num_categories\n",
        "\n",
        "    # Extract image path and image name\n",
        "    # For GCS URLs like gs://bucket/folder/subfolder/image.jpg\n",
        "    # image_path should be gs://bucket/folder/subfolder/\n",
        "    # image_name should be image.jpg\n",
        "    try:\n",
        "        # Remove 'gs://' prefix\n",
        "        path_without_scheme = image_url[5:]\n",
        "        # Split into bucket and the rest of the path\n",
        "        bucket_part, path_part = path_without_scheme.split('/', 1)\n",
        "        # Get image_path by removing the image name\n",
        "        image_path = f\"gs://{bucket_part}/{os.path.dirname(path_part)}/\"\n",
        "        # Get image_name\n",
        "        image_name = os.path.basename(path_part)\n",
        "    except ValueError:\n",
        "        # Handle cases where there might not be a subfolder\n",
        "        # e.g., gs://bucket/image.jpg\n",
        "        bucket_part = image_url[5:].split('/', 1)[0]\n",
        "        image_path = f\"gs://{bucket_part}/\"\n",
        "        image_name = os.path.basename(image_url)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing image URL '{image_url}': {e}\")\n",
        "        image_path = image_url  # Fallback to full URL\n",
        "        image_name = 'Unknown'\n",
        "\n",
        "    # Create a dictionary for the new row, including image_path and image_name\n",
        "    row_dict = {\n",
        "        'image_path': image_path,\n",
        "        'image_name': image_name\n",
        "    }\n",
        "    row_dict.update({category_names[i]: parsed_data[i] for i in range(num_categories)})\n",
        "\n",
        "    # Convert the row dictionary to a DataFrame\n",
        "    new_row = pd.DataFrame([row_dict])\n",
        "\n",
        "    # Concatenate the new row to the existing DataFrame\n",
        "    df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "    # Save the updated DataFrame to Excel with support for Chinese characters\n",
        "    try:\n",
        "        df.to_excel(EXCEL_FILE_PATH, index=False, engine='openpyxl')\n",
        "        print(f\"Saved results to {EXCEL_FILE_PATH}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving to Excel: {e}\")\n",
        "\n",
        "    # Optional: Introduce a short delay to respect API rate limits\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"\\nProcessing completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "rVVTeOobCoVU",
        "outputId": "0bfb100c-41dc-471a-91c1-432ba2aa15d5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized new DataFrame with 'image_path' and 'image_name' columns.\n",
            "Total images found: 300\n",
            "\n",
            "Processing image 1/300: gs://cuhk_fashion_project_2024_batch_1/Ellasay/ELLASSAY_歌力思_1.jpg\n",
            "API call failed: Error code: 404 - [{'error': {'code': 404, 'message': 'Publisher Model `projects/324474596293/locations/us-central1/publishers/publisher/models/model` not found.', 'status': 'NOT_FOUND'}}]\n",
            "Error during API call: Error code: 404 - [{'error': {'code': 404, 'message': 'Publisher Model `projects/324474596293/locations/us-central1/publishers/publisher/models/model` not found.', 'status': 'NOT_FOUND'}}]. Retry 1/3 after delay.\n",
            "API call failed: Error code: 404 - [{'error': {'code': 404, 'message': 'Publisher Model `projects/324474596293/locations/us-central1/publishers/publisher/models/model` not found.', 'status': 'NOT_FOUND'}}]\n",
            "Error during API call: Error code: 404 - [{'error': {'code': 404, 'message': 'Publisher Model `projects/324474596293/locations/us-central1/publishers/publisher/models/model` not found.', 'status': 'NOT_FOUND'}}]. Retry 2/3 after delay.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-2848ca5ce2f2>\u001b[0m in \u001b[0;36m<cell line: 169>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# Call the API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_llama_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mresponse_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'choices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-2848ca5ce2f2>\u001b[0m in \u001b[0;36mcall_llama_api\u001b[0;34m(image_url, prompt, max_tokens, temperature, top_p)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1277\u001b[0m         )\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - [{'error': {'code': 404, 'message': 'Publisher Model `projects/324474596293/locations/us-central1/publishers/publisher/models/model` not found.', 'status': 'NOT_FOUND'}}]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-2848ca5ce2f2>\u001b[0m in \u001b[0;36m<cell line: 169>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mretries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error during API call: {e}. Retry {retries}/{max_retries} after delay.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_openai_api_llama3_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}